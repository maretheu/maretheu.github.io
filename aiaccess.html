<!DOCTYPE html>
<html lang="en">
<head>
    <title>The Home of Zone</title>

    <!-- Style -->
    <style>
        h1{
            text-align: center;
        }
        body{
            width: 50% ;
            margin: auto;
        }
        .dark-mode{
            background-color: black;
            color: lightblue;
        }
    </style>
    <script type="text/javascript">
        function darkMode(){
            document.body.classList.toggle('dark-mode');
        }
    </script>

</head>
<body>

    <h1> <!-- Header -->
        <b> AI has great potential to improve accessibility and create a more equitable world but with how often AI systems are biased we must be careful not to make things worse. </b>
    </h1>

    <p>
        It is always good when new methods of increasing accessibility are created and the use of artificial intelligence to this end has great potential to do good and make the world more accessible for everyone within it. The emphasis of the article on accessibility specifically within the context of a company workplace however, is something that is somewhat concerning as it emphasizes the productivity and value produced by neurodivergent people as opposed to actually prioritizing making their lives easier and as a result ends up feeling slightly dehumanizing. In addition to simply being dehumanizing, this prioritization of profits, productivity, and produced value naturally creates the risk that those with neurodivergence or disability which cannot be easily profited from would be left behind to suffer without any meaningful support or gain from these new artificial intelligences.
        <br>
        <br>
        Another major concern with this adoption of artificial intelligence with the proclaimed goal of improving accessibility is the simple question of whether or not it actually does so. And if it does not significantly improve accessibility what is it doing instead? These articles seem to gloss over and overlook some of the questions that could be raised about how some of these developments in artificial intelligence could be used for great harm, which is something that i feel should be addressed. Artificial intelligence used for facial recognition could be used to resolve captchas and open phones but it can also be used to track down and arrest protesters, furthermore there are many examples of these sorts of systems being used in this sort of actively malicious manner.
        <br>
        <br>
        Even if the artificial intelligence systems are not used at all in this sort of actively malicious and harmful manner it is still incredibly easy to accidentally make a system that internalizes unconscious biases from its creators and perpetuates them in a directly harmful manner. For example there have been many instances of facial recognition programs having substantial trouble with people of color. Even in instances where artificial intelligence has been utilized with the goal of reducing harm and increasing equity that does not always end up being how things turn out and if we are hoping to increase accessibility and equity through the use of these technologies it is vital that we are aware of the risks and the ways in which they have failed in the past so that we can better work to avoid those downfalls and truly succeed in achieving what we set out to do.
    </p>

    <div style="text-align: center;">
        <button onclick="darkMode()">Toggle Dark Mode</button>
    </div>

</body>
</html>
